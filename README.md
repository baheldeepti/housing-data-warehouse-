# ğŸ¡ Nashville Housing Data Warehouse

> Turning CSV chaos into a clean, storyâ€‘driven analytics platform.

---

## ğŸ“– TableÂ ofÂ Contents

1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [TechÂ Stack](#tech-stack)
4. [QuickÂ Start](#quick-start)
5. [Data Model](#data-model)
6. [Usage Examples](#usage-examples)
7. [Contributing](#contributing)
8. [License](#license)
9. [Acknowledgments](#acknowledgments)

---

## ProjectÂ Overview

Nashvilleâ€™s openâ€‘data portal publishes property and housing records as adâ€‘hoc CSV exports.  Analysts had to wrestle with messy files, inconsistent headers, and missing keys before any insight work could begin.

This repository **automates the entire journey** from raw CSVs to a governed starâ€‘schema warehouse, complete with CI tests and documentation.  The goal: *insight in minutes, not days.*

<p align="center">
  <img src="docs/img/etl_flow.png" width="650" alt="ETL Flow diagram"/>
</p>

---

## Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   scrape + ingest   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub CI â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Object     â”‚
â”‚  Actions    â”‚                    â”‚   Storage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ build + push                        â”‚
        â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Compose                 â”‚
â”‚  â€¢ Postgres  â€¢ pgAdmin  â€¢ dbt  â€¢ Data Ingester    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚          transform + test
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     modeled tables     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RawÂ Schema â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Analytics  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚  Schema    â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **Ingestion**: Python ingester fetches weekly CSV drops and stages them in Postgres.
* **Transformation**: `dbt` builds incremental models, applies tests, and generates docs.
* **Orchestration**: GitHub Actions triggers CI on pullâ€‘request; local dev via `dockerâ€‘compose`.

---

## TechÂ Stack

| Layer             | Tool / Lib        | Purpose                            |
| ----------------- | ----------------- | ---------------------------------- |
| **Storage**       | Postgres 16       | Columnâ€‘friendly OLTP/OLAP hybrid   |
| **Transform**     | dbt CoreÂ v1.10    | SQLâ€‘centric modeling & testing     |
| **Compute**       | Docker Compose    | Reproducible local dev environment |
| **Orchestration** | GitHubÂ Actions    | CI/CD, linting, model tests        |
| **Visualization** | PowerÂ BI (sample) | Dashboards on star schema          |

---

## QuickÂ Start

```bash
# 1ï¸âƒ£  Clone
$ git clone https://github.com/<your-org>/nashville-data-warehouse.git
$ cd nashville-data-warehouse

# 2ï¸âƒ£  Spin up the stack (detached)
$ docker compose up -d

# 3ï¸âƒ£  Seed sample CSVs
$ docker compose exec ingester python ingest.py --run-once

# 4ï¸âƒ£  Run dbt models + tests
$ docker compose exec dbt_runner dbt build --targets dev

# 5ï¸âƒ£  Open pgAdmin â†’ explore ğŸ¡
```

â„¹ï¸  *Default credentials: `postgres / postgres` (change in `.env`).*

---

## Data Model

The warehouse follows a **star schema** centered on property sales.

```text
             dim_date
                â†‘
 dim_property â† fct_property_sale â†’ dim_owner
                â†“
            dim_location
```

See [`models/core/`](models/core/) for the SQL that builds each table.

---

## Usage Examples

```sql
-- Total sales volume by year
SELECT d.year,
       SUM(f.sale_price) AS total_sales
FROM fct_property_sale f
JOIN dim_date d ON f.date_key = d.date_key
GROUP BY d.year
ORDER BY d.year;
```

More examples live in [`analysis/queries/`](analysis/queries).

---

## Contributing

1. **Fork** the repo & create a feature branch.
2. Run `pre-commit` hooks (`black`, `sqlfmt`).
3. Open a PR; GitHub Actions will run unit & model tests.
4. After review, squash & merge.

---


## Acknowledgments

* ğŸ—º Original CSV dataset from [Nashville Open Data Portal](https://data.nashville.gov/).
* ğŸ¨ Diagram style inspired by [dbdiagram.io](https://dbdiagram.io/).
* ğŸ™ Hat tip to the **dbt**, **Postgres**, and **Docker** communities for rockâ€‘solid tooling.

---

<p align="center">
  <sub>Made with â¤ï¸  by DeeptiÂ Bahel & contributors</sub>
</p>
# housing-data-warehouse-
